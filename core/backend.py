import queue
import numpy as np
import gtsam
from gtsam.symbol_shorthand import X, V, B, L
import re
from utils.debug import Debugger

class Backend:
    def __init__(self, global_central_map, config, imu_processor):
        self.global_central_map = global_central_map
        self.config = config

        # ä½¿ç”¨ iSAM2 ä½œä¸ºä¼˜åŒ–å™¨
        parameters = gtsam.ISAM2Params()
        parameters.setRelinearizeThreshold(0.1) 
        parameters.relinearizeSkip = 1
        self.isam2 = gtsam.ISAM2(parameters)
        
        # çŠ¶æ€ä¸idç®¡ç†
        self.kf_id_to_gtsam_id = {}
        self.landmark_id_to_gtsam_id = {}
        self.next_gtsam_kf_id = 0
        
        # è·å–ç›¸æœºå†…ã€å¤–å‚
        cam_intrinsics = np.asarray(self.config.get('cam_intrinsics')).reshape(3, 3)
        self.K = gtsam.Cal3_S2(cam_intrinsics[0, 0], cam_intrinsics[1, 1], 0, 
                               cam_intrinsics[0, 2], cam_intrinsics[1, 2])

        T_bc_raw = self.config.get('T_bc', np.eye(4).flatten().tolist())
        self.T_bc = np.asarray(T_bc_raw).reshape(4, 4)
        self.body_T_cam = gtsam.Pose3(self.T_bc)
        self.cam_T_body = self.body_T_cam.inverse()

        # å­˜å‚¨æœ€æ–°çš„ä¼˜åŒ–åçš„åç½®ï¼Œç”¨äºIMUé¢„ç§¯åˆ†
        self.latest_bias = gtsam.imuBias.ConstantBias()

        # è®°å½•ä¼˜åŒ–è¯¯å·®ï¼Œdebugç”¨
        self.logger = Debugger(file_prefix="backend", column_names=["error"])

    # å…³é”®å¸§idæ˜ å°„åˆ°å›¾çš„id
    def _get_kf_gtsam_id(self, kf_id):
        if kf_id not in self.kf_id_to_gtsam_id:
            self.kf_id_to_gtsam_id[kf_id] = self.next_gtsam_kf_id
            self.next_gtsam_kf_id += 1
        return self.kf_id_to_gtsam_id[kf_id]

    # è·¯æ ‡ç‚¹idæ˜ å°„åˆ°å›¾çš„id
    def _get_lm_gtsam_id(self, lm_id):
        if lm_id not in self.landmark_id_to_gtsam_id:
            self.landmark_id_to_gtsam_id[lm_id] = lm_id
        return self.landmark_id_to_gtsam_id[lm_id]

    def get_latest_optimized_state(self):
        if self.next_gtsam_kf_id == 0:
            return None, None, None
        
        latest_gtsam_id = self.next_gtsam_kf_id - 1
        result = self.isam2.calculateEstimate()

        try:
            pose = result.atPose3(X(latest_gtsam_id))
            velocity = result.atVector(V(latest_gtsam_id))
            bias = result.atConstantBias(B(latest_gtsam_id))
            return pose, velocity, bias
        except Exception as e:
            print(f"[Error][Backend] Failed to retrieve latest state for gtsam_id {latest_gtsam_id}: {e}")
            return None, None, None

    def update_estimator_map(self, keyframe_window, landmarks):
        print("ã€Backendã€‘: Syncing optimized results back to Estimator...")
        optimized_results = self.isam2.calculateEstimate()

        # æ›´æ–°å…³é”®å¸§ä½å§¿
        for kf in keyframe_window:
           # è·å–å¾…æ›´æ–°å…³é”®å¸§çš„gtsam_id
            gtsam_id = self.kf_id_to_gtsam_id.get(kf.get_id())
            if gtsam_id is not None and optimized_results.exists(X(gtsam_id)):
                
                # ä»ä¼˜åŒ–ç»“æœä¸­è·å–æœ€æ–°çš„IMUä½å§¿ T_w_b
                pose_w_b = optimized_results.atPose3(X(gtsam_id))
                
                # è½¬æ¢å›ç›¸æœºä½å§¿ T_w_c å¹¶æ›´æ–°
                pose_w_c = pose_w_b.compose(self.body_T_cam)
                kf.set_global_pose(pose_w_c.matrix())

        # æ›´æ–°è·¯æ ‡ç‚¹åæ ‡
        for lm_id, landmark_obj in landmarks.items():
            gtsam_id = self._get_lm_gtsam_id(lm_id)
            if gtsam_id is not None and optimized_results.exists(L(gtsam_id)):
                # 1. ä»ä¼˜åŒ–ç»“æœä¸­è·å–æœ€æ–°çš„3Dåæ ‡
                optimized_position = optimized_results.atPoint3(L(gtsam_id))
                # 2. è°ƒç”¨å¯¹è±¡çš„æ–¹æ³•æ¥æ›´æ–°å…¶å†…éƒ¨çŠ¶æ€
                landmark_obj.set_triangulated(optimized_position)

    def remove_stale_landmarks(self, stale_lm_ids):
        print(f"ã€Backendã€‘: Receiving command to remove {len(stale_lm_ids)} stale landmarks.")
        if not stale_lm_ids:
            return
        
        stale_lm_ids = {gtsam.Symbol('l', self._get_lm_gtsam_id(lm_id)) for lm_id in stale_lm_ids}
        graph = self.isam2.getFactorsUnsafe()
        factor_indices_to_remove = []
        stale_lm_keys = []
        # print(f"ã€TESTã€‘: {stale_lm_keys.keys()}")

        for symbol_obj in stale_lm_ids:
            stale_lm_keys.append(symbol_obj.key())

        # éå†å›¾ï¼Œæ‰¾åˆ°éœ€è¦åˆ é™¤çš„å› å­ç´¢å¼•
        for i in range(graph.size()):
            factor = graph.at(i)
            if factor:
                for key in factor.keys():
                    if key in stale_lm_keys:
                        # print(f"ğŸ•µï¸â€ [Trace l{key}]: Found stale factor at index {i}")
                        factor_indices_to_remove.append(i)
                        break
        
        if factor_indices_to_remove:
            empty_graph = gtsam.NonlinearFactorGraph()
            empty_values = gtsam.Values()
            self.isam2.update(empty_graph, empty_values, factor_indices_to_remove)
            print(f"ã€Backendã€‘: Removed {len(factor_indices_to_remove)} stale factors.")

        # åˆ é™¤è·¯æ ‡ç‚¹idæ˜ å°„
        for lm_id in stale_lm_ids:
            if lm_id in self.landmark_id_to_gtsam_id:
                del self.landmark_id_to_gtsam_id[lm_id]

    def initialize_optimize(self, initial_keyframes, initial_imu_factors, initial_landmarks, initial_velocities, initial_bias):
        print("ã€Backendã€‘: Initializing optimize...")

        graph = gtsam.NonlinearFactorGraph()
        estimates = gtsam.Values()

        for i, kf in enumerate(initial_keyframes):
            kf_gtsam_id = self._get_kf_gtsam_id(kf.get_id())
            
            # ä»åˆå§‹åŒ–ç»“æœä¸­è·å–ä½å§¿ã€é€Ÿåº¦å’Œåç½®
            T_wc = gtsam.Pose3(kf.get_global_pose())
            T_wb = T_wc.compose(self.cam_T_body)
            # initial_velocities æ˜¯ä¸€ä¸ªæ‰å¹³åŒ–çš„æ•°ç»„ï¼Œæ¯3ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªé€Ÿåº¦å‘é‡
            velocity = initial_velocities[i*3 : i*3+3]
            
            # æ‰€æœ‰å¸§ä½¿ç”¨ç›¸åŒçš„åˆå§‹åç½®
            bias = initial_bias

            estimates.insert(X(kf_gtsam_id), T_wb)
            estimates.insert(V(kf_gtsam_id), velocity)
            estimates.insert(B(kf_gtsam_id), bias)

            # ä¸ºç¬¬ä¸€å¸§æ·»åŠ å¼ºå…ˆéªŒ
            if kf_gtsam_id == 0:
                prior_pose_noise = gtsam.noiseModel.Diagonal.Sigmas(np.array([1e-6]*3 + [1e-4]*3))
                prior_vel_noise = gtsam.noiseModel.Diagonal.Sigmas(np.array([1e-4] * 3))
                prior_bias_noise = gtsam.noiseModel.Diagonal.Sigmas(np.array([1e-2]*3 + [1e-3]*3))
                graph.add(gtsam.PriorFactorPose3(X(0), T_wb, prior_pose_noise))
                graph.add(gtsam.PriorFactorVector(V(0), velocity, prior_vel_noise))
                graph.add(gtsam.PriorFactorConstantBias(B(0), bias, prior_bias_noise))
            elif kf_gtsam_id == len(initial_keyframes) - 1:
                # ä¸ºæœ€åä¸€å¸§æ·»åŠ è¾ƒå¼±çš„ä½ç½®å…ˆéªŒä»¥ç¨³å®šå°ºåº¦
                prior_pose_noise = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.1]*3 + [0.5]*3))
                graph.add(gtsam.PriorFactorPose3(X(kf_gtsam_id), T_wb, prior_pose_noise))

        # æ·»åŠ æ‰€æœ‰åˆå§‹IMUå› å­
        for factor_data in initial_imu_factors:
            start_kf = next(kf for kf in initial_keyframes if kf.get_timestamp() == factor_data['start_kf_timestamp'])
            end_kf = next(kf for kf in initial_keyframes if kf.get_timestamp() == factor_data['end_kf_timestamp'])
            gtsam_id1 = self._get_kf_gtsam_id(start_kf.get_id())
            gtsam_id2 = self._get_kf_gtsam_id(end_kf.get_id())
            pim = factor_data['imu_preintegration']
            graph.add(gtsam.CombinedImuFactor(X(gtsam_id1), V(gtsam_id1), X(gtsam_id2), V(gtsam_id2), B(gtsam_id1), B(gtsam_id2), pim))

        # æ·»åŠ æ‰€æœ‰åˆå§‹è·¯æ ‡ç‚¹å˜é‡å’Œè§†è§‰å› å­
        visual_factor_noise = gtsam.noiseModel.Isotropic.Sigma(2, 3.0)
        for lm_id, lm_3d_pos in initial_landmarks.items():
            lm_gtsam_id = self._get_lm_gtsam_id(lm_id)
            estimates.insert(L(lm_gtsam_id), lm_3d_pos)

        for kf in initial_keyframes:
            kf_gtsam_id = self._get_kf_gtsam_id(kf.get_id())
            for lm_id, pt_2d in zip(kf.get_visual_feature_ids(), kf.get_visual_features()):
                # åªå¤„ç†æœ¬æ¬¡ä¼˜åŒ–ä¸­æ–°æ·»åŠ çš„landmark
                if lm_id in initial_landmarks:
                    lm_gtsam_id = self._get_lm_gtsam_id(lm_id)
                    factor = gtsam.GenericProjectionFactorCal3_S2(pt_2d, visual_factor_noise, X(kf_gtsam_id), L(lm_gtsam_id), self.K, body_P_sensor=self.body_T_cam)
                    graph.add(factor)

        # æ‰§è¡ŒiSAM2çš„ç¬¬ä¸€æ¬¡æ›´æ–°ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰
        print(f"ã€Backendã€‘: Initializing iSAM2 with {graph.size()} new factors and {estimates.size()} new values...")
        self.isam2.update(graph, estimates)
        for _ in range(2): self.isam2.update()
        
        # è®°å½•ä¼˜åŒ–è¯¯å·®
        self._log_optimization_error(graph)

        # æ›´æ–°æœ€æ–°bias
        _, _, latest_bias = self.get_latest_optimized_state()
        if latest_bias is not None:
            self.latest_bias = latest_bias
        print("ã€Backendã€‘: Initial graph optimization complete.")


    def optimize_incremental(self, last_keyframe, new_keyframe, new_imu_factors, 
                            new_landmarks, new_visual_factors, initial_state_guess):

        new_graph = gtsam.NonlinearFactorGraph()
        new_estimates = gtsam.Values()

        # æ·»åŠ æ–°å…³é”®å¸§çš„çŠ¶æ€å˜é‡ï¼Œä½¿ç”¨IMUé¢„æµ‹å€¼ä½œä¸ºåˆå§‹ä¼°è®¡
        kf_gtsam_id = self._get_kf_gtsam_id(new_keyframe.get_id())
        T_wb_guess, vel_guess, bias_guess = initial_state_guess

        new_estimates.insert(X(kf_gtsam_id), T_wb_guess)
        new_estimates.insert(V(kf_gtsam_id), vel_guess)
        new_estimates.insert(B(kf_gtsam_id), bias_guess)

        # æ·»åŠ IMUå› å­
        last_kf_gtsam_id = self._get_kf_gtsam_id(last_keyframe.get_id())
        pim = new_imu_factors['imu_preintegration']
        imu_factor = gtsam.CombinedImuFactor(
            X(last_kf_gtsam_id), V(last_kf_gtsam_id), X(kf_gtsam_id), V(kf_gtsam_id),
            B(last_kf_gtsam_id), B(kf_gtsam_id), pim)
        new_graph.add(imu_factor)

        # æ·»åŠ æ–°è·¯æ ‡ç‚¹é¡¶ç‚¹ï¼Œæ³¨æ„è¿™é‡Œæ·»åŠ çš„é¡¶ç‚¹åªåœ¨new_estimatesä¸­è¿˜æ²¡æœ‰è¿›å…¥isam2çš„å›¾
        for lm_id, lm_3d_pos in new_landmarks.items():
            lm_gtsam_id = self._get_lm_gtsam_id(lm_id)
            # æ£€æŸ¥ï¼š1) ä¸åœ¨æ—§å›¾ä¸­ï¼Œ2) è¿˜æ²¡è¢«æ·»åŠ è¿‡ ç¡®ä¿é¡¶ç‚¹åªè¢«æ·»åŠ ä¸€æ¬¡
            if not self.isam2.getLinearizationPoint().exists(L(lm_gtsam_id)):
                new_estimates.insert(L(lm_gtsam_id), lm_3d_pos)
        
        # æ·»åŠ é‡æŠ•å½±å› å­ï¼Œå‰é¢å·²ç»æ·»åŠ äº†æ–°è·¯æ ‡ç‚¹é¡¶ç‚¹ï¼Œæ‰€ä»¥è¿™é‡Œåªéœ€è¦æ·»åŠ å†å²ç‚¹å’Œæ–°ç‰¹å¾ç‚¹çš„è§‚æµ‹å¸§é‡æŠ•å½±å› å­
        visual_factor_noise = gtsam.noiseModel.Isotropic.Sigma(2, 3.0)
        current_isam_values = self.isam2.getLinearizationPoint()
        for kf_id, lm_id, pt_2d in new_visual_factors:
            kf_gtsam_id = self._get_kf_gtsam_id(kf_id)
            lm_gtsam_id = self._get_lm_gtsam_id(lm_id)

            kf_exists = current_isam_values.exists(X(kf_gtsam_id)) or new_estimates.exists(X(kf_gtsam_id))
            lm_exists = current_isam_values.exists(L(lm_gtsam_id)) or new_estimates.exists(L(lm_gtsam_id))

            if kf_exists and lm_exists:
                factor = gtsam.GenericProjectionFactorCal3_S2(pt_2d, visual_factor_noise, X(kf_gtsam_id), L(lm_gtsam_id), self.K, body_P_sensor=self.body_T_cam)
                new_graph.add(factor)

        # æ‰§è¡ŒiSAM2å¢é‡æ›´æ–°
        print(f"ã€Backendã€‘: Updating iSAM2 ({new_graph.size()} new factors, {new_estimates.size()} new variables)...")
        
        # try:
        self.isam2.update(new_graph, new_estimates)
        for _ in range(2): self.isam2.update()

        # è®°å½•ä¼˜åŒ–è¯¯å·®
        self._log_optimization_error(new_graph)

        # except RuntimeError as e:
        #     print("\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
        #     print("!!!!!!!!!! OPTIMIZATION FAILED !!!!!!!!!!!!!!")
        #     print(f"ERROR: {e}")

        # æ›´æ–°æœ€æ–°bias
        _, _, latest_bias = self.get_latest_optimized_state()
        if latest_bias is not None:
            self.latest_bias = latest_bias
        print("ã€Backendã€‘: Incremental optimization complete.")

    def _log_optimization_error(self, new_factors_graph):
        try:
            optimized_result = self.isam2.calculateEstimate()
            current_full_graph = self.isam2.getFactorsUnsafe()
            total_error = current_full_graph.error(optimized_result)
            new_factors_error = new_factors_graph.error(optimized_result)

            print(f"ã€Backendã€‘ä¼˜åŒ–è¯¯å·®ç»Ÿè®¡: "
                  f"æœ¬è½®æ–°å¢å› å­è¯¯å·® = {new_factors_error:.4f}, "
                  f"å½“å‰å›¾æ€»è¯¯å·® = {total_error:.4f}")
            
            self.logger.log(total_error)
    
        except Exception as e:
            print(f"[Error][Backend] è®¡ç®—ä¼˜åŒ–è¯¯å·®æ—¶å‡ºé”™: {e}")
